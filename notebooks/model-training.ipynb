{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "# module = os.path.abspath('/home/learner/DLA_project/src/main')\n",
    "module = os.path.abspath(\"C:/Users\\\\18145\\\\development\\\\wesad_experiments\\\\src\\\\main\")\n",
    "if module not in sys.path:\n",
    "    sys.path.append(module)\n",
    "from DataManager import DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from S2\n",
      "\tPath=C:\\WESAD\\S2\\S2.pkl\n",
      "Loading data from S3\n",
      "\tPath=C:\\WESAD\\S3\\S3.pkl\n",
      "Loading data from S4\n",
      "\tPath=C:\\WESAD\\S4\\S4.pkl\n",
      "Loading data from S5\n",
      "\tPath=C:\\WESAD\\S5\\S5.pkl\n",
      "Loading data from S6\n",
      "\tPath=C:\\WESAD\\S6\\S6.pkl\n",
      "Loading data from S7\n",
      "\tPath=C:\\WESAD\\S7\\S7.pkl\n",
      "Loading data from S8\n",
      "\tPath=C:\\WESAD\\S8\\S8.pkl\n",
      "Loading data from S9\n",
      "\tPath=C:\\WESAD\\S9\\S9.pkl\n",
      "Loading data from S10\n",
      "\tPath=C:\\WESAD\\S10\\S10.pkl\n",
      "Loading data from S11\n",
      "\tPath=C:\\WESAD\\S11\\S11.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "manager.load_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conputing features..\n",
      "Considering subject  2\n",
      "Considering subject  3\n",
      "Considering subject  4\n",
      "Considering subject  5\n",
      "Considering subject  6\n",
      "Considering subject  7\n",
      "Considering subject  8\n",
      "Considering subject  9\n",
      "Considering subject  10\n",
      "Considering subject  11\n",
      "conputing features..\n",
      "Considering subject  2\n",
      "Considering subject  3\n",
      "Considering subject  4\n",
      "Considering subject  5\n",
      "Considering subject  6\n",
      "Considering subject  7\n",
      "Considering subject  8\n",
      "Considering subject  9\n",
      "Considering subject  10\n",
      "Considering subject  11\n"
     ]
    }
   ],
   "source": [
    "manager.compute_features();\n",
    "manager.compute_features_stress();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10  subjects\n",
      "there are  44461  values for  a_mean\n",
      "[0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773]\n",
      "there are  44461  values for  a_std\n",
      "[-0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962]\n",
      "there are  44461  values for  a_maxx\n",
      "[-0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928]\n",
      "there are  44461  values for  a_maxy\n",
      "[-0.1681766395512081, -0.16820373953666, -0.1682159157196681, -0.16822052995931536, -0.16817386801469902, -0.16810921560015002, -0.16804839175513808, -0.16799597744998485, -0.167943796508369, -0.16789020597508975, -0.16785491549826792]\n",
      "there are  44461  values for  a_maxz\n",
      "[0.018150791410807637, 0.018153852199080042, 0.018155388200807383, 0.01816366217156312, 0.018098480896898087, 0.018049710117182687, 0.018029910512462825, 0.017971771785544866, 0.01794856213048406, 0.01793648580576654, 0.017917797155686754]\n",
      "there are  44461  values for  e_max\n",
      "[1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625]\n",
      "there are  44461  values for  e_min\n",
      "[1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875]\n",
      "there are  44461  values for  e_mean\n",
      "[1.256753022330148, 1.2564663750784737, 1.2561790829613095, 1.2558757509504046, 1.2555773689633325, 1.2552835464477539, 1.2549859183175223, 1.2546887534005302, 1.2544013522920154, 1.2541091101510184, 1.2538137708391461]\n",
      "there are  44461  values for  e_range\n",
      "[0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875]\n",
      "there are  44461  values for  e_std\n",
      "[0.027996115056521168, 0.027978663566655466, 0.027968531671524306, 0.027930017594235457, 0.027900964709956896, 0.02788097863880627, 0.02786017275544809, 0.027840284597997103, 0.027826475246974486, 0.027801530045377415, 0.02779012605506253]\n",
      "there are  44461  values for  t_max\n",
      "[28.456024, 28.456024, 28.456024, 28.463135, 28.463135, 28.557465, 28.557465, 28.557465, 28.557465, 28.557465, 28.557465]\n",
      "there are  44461  values for  t_min\n",
      "[28.045258, 28.045258, 28.045258, 28.045258, 28.045258, 28.045258, 28.045258, 28.045258, 28.045258, 28.045258, 28.045258]\n",
      "there are  44461  values for  t_mean\n",
      "[28.21592, 28.21635, 28.216797, 28.217257, 28.217714, 28.218203, 28.218681, 28.21911, 28.2196, 28.220066, 28.22053]\n",
      "there are  44461  values for  t_range\n",
      "[0.4107666, 0.4107666, 0.4107666, 0.4178772, 0.4178772, 0.51220703, 0.51220703, 0.51220703, 0.51220703, 0.51220703, 0.51220703]\n",
      "there are  44461  values for  t_std\n",
      "[0.055632006, 0.055853903, 0.056076307, 0.05630139, 0.05653354, 0.056806758, 0.057019647, 0.05716957, 0.057364658, 0.057513, 0.057683818]\n"
     ]
    }
   ],
   "source": [
    "print(\"We have\", len(manager.SUBJECTS), \" subjects\")\n",
    "\n",
    "for feature in manager.FEATURES.keys():\n",
    "    print(\"there are \", len(manager.FEATURES[feature]), \" values for \", feature)\n",
    "#     print(manager.FEATURES[feature][3277:3288])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44461, 15)\n",
      "(44461, 15)\n",
      "(23780, 15)\n",
      "(23780, 15)\n"
     ]
    }
   ],
   "source": [
    "# Lets go ahead and reshape this data such that we have\n",
    "# samples, features = [N, 15]\n",
    "\n",
    "X1 = []\n",
    "X2 = []\n",
    "for i in range(0,  len(manager.FEATURES['a_mean'])):\n",
    "    X1.append([manager.FEATURES['a_mean'][i], manager.FEATURES['a_std'][i], manager.FEATURES['a_maxx'][i], manager.FEATURES['a_maxy'][i], manager.FEATURES['a_maxz'][i],\\\n",
    "                  manager.FEATURES['e_max'][i], manager.FEATURES['e_min'][i], manager.FEATURES['e_mean'][i], manager.FEATURES['e_range'][i], manager.FEATURES['e_std'][i],\\\n",
    "                  manager.FEATURES['t_max'][i], manager.FEATURES['t_min'][i], manager.FEATURES['t_mean'][i], manager.FEATURES['t_range'][i], manager.FEATURES['t_std'][i]])\n",
    "\n",
    "# X1 = np.hstack([manager.FEATURES['a_mean'], manager.FEATURES['a_std'], manager.FEATURES['a_maxx'], manager.FEATURES['a_maxy'], manager.FEATURES['a_maxz'],\\\n",
    "#                   manager.FEATURES['e_max'], manager.FEATURES['e_min'], manager.FEATURES['e_mean'], manager.FEATURES['e_range'], manager.FEATURES['e_std'],\\\n",
    "#                   manager.FEATURES['t_max'], manager.FEATURES['t_min'], manager.FEATURES['t_mean'], manager.FEATURES['t_range'], manager.FEATURES['t_std']] )\n",
    "\n",
    "print(np.shape(X1))\n",
    "\n",
    "# X1 = np.reshape(X1, (len(manager.FEATURES['a_mean']), 15))\n",
    "\n",
    "print(np.shape(X1))\n",
    "\n",
    "for i in range(0,  len(manager.STRESS_FEATURES['a_mean'])):\n",
    "    X2.append([manager.STRESS_FEATURES['a_mean'][i], manager.STRESS_FEATURES['a_std'][i], manager.STRESS_FEATURES['a_maxx'][i], manager.STRESS_FEATURES['a_maxy'][i], manager.STRESS_FEATURES['a_maxz'][i],\\\n",
    "                  manager.STRESS_FEATURES['e_max'][i], manager.STRESS_FEATURES['e_min'][i], manager.STRESS_FEATURES['e_mean'][i], manager.STRESS_FEATURES['e_range'][i], manager.STRESS_FEATURES['e_std'][i],\\\n",
    "                  manager.STRESS_FEATURES['t_max'][i], manager.STRESS_FEATURES['t_min'][i], manager.STRESS_FEATURES['t_mean'][i], manager.STRESS_FEATURES['t_range'][i], manager.STRESS_FEATURES['t_std'][i]] )\n",
    "print(np.shape(X2))\n",
    "\n",
    "# X2 = np.reshape(X2, (len(manager.STRESS_FEATURES['a_mean']), 15))\n",
    "\n",
    "print(np.shape(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.145400047302246, 0.042999982833862305, 0.6109999418258667, 0.16599110373712722, 0.415284791772234, 5.7567596435546875, 4.2156219482421875, 4.9314933776855465, 1.5411376953125, 0.2716493622293986, 29.426208, 28.954346, 29.156557, 0.4718628, 0.07528099]\n",
      "[0.9595999717712402, -0.03659999370574951, -0.18699997663497925, 0.4916953622968424, 0.04776767636961479, 1.355743408203125, 0.968170166015625, 1.2124954586937313, 0.3875732421875, 0.033031472600536266, 31.531494, 31.170837, 31.334574, 0.36065674, 0.050243504]\n"
     ]
    }
   ],
   "source": [
    "print(X1[0])\n",
    "print(X2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246]\n",
      "[-0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219]\n",
      "[0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667]\n"
     ]
    }
   ],
   "source": [
    "print(manager.FEATURES['a_mean'][100:110])\n",
    "\n",
    "print(manager.FEATURES['a_std'][400:410])\n",
    "\n",
    "print(manager.FEATURES['a_maxx'][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pip\n",
    "\n",
    "# try:\n",
    "#     import keras\n",
    "# except ImportError:\n",
    "#     ! sudo pip3 install keras\n",
    "# try:\n",
    "#     import h5py\n",
    "# except ImportError:\n",
    "#     ! sudo pip3 install h5py\n",
    "# try:\n",
    "#     import ibmiotf\n",
    "# except ImportError:\n",
    "#     ! sudo pip3 install ibmiotf\n",
    "# try:\n",
    "#     import tensorflow\n",
    "# except ImportError:\n",
    "#     ! sudo pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import sklearn\n",
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0712 21:18:21.967104 17924 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0712 21:18:21.968798 17924 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0712 21:18:21.969967 17924 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0712 21:18:22.043764 17924 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8, )\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "session = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 is the baseline data\n",
    "# x2 is the stress data\n",
    "\n",
    "y1 = [0] * len(X1)\n",
    "y2 = [1] * len(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44461\n",
      "23780\n"
     ]
    }
   ],
   "source": [
    "print(len(y1))\n",
    "print(len(y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to concat the data between baseline and stress so that we can split it into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68241, 15)\n",
      "(68241,)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((X1, X2), axis=0)\n",
    "print(np.shape(X))\n",
    "\n",
    "y = np.concatenate((y1,y2), axis=0)\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data up in train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# since we don't have the same number of samples for x and y, \n",
    "# we will drop off some x values for creating the sample\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51180, 15)\n",
      "(17061, 15)\n",
      "(51180,)\n",
      "(17061,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to scale the data and hope we get better results.\n",
    "1. fit the scaler to the training data (fit_transform)\n",
    "2. transform training data with the scaler\n",
    "3. fit the model with transformed data\n",
    "4. transform test data with the scaler\n",
    "5. predict using model and output of (4)\n",
    "\n",
    "It will be better to have our data scaled between 0 and 1, so lets go ahead and create a function to \n",
    "normalize the data that way now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    return scaler.fit_transform(data)\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be\n",
    "\n",
    "# input_shape=(number of sequences=?, time_steps=None, features=15)\n",
    "\n",
    "# target=(number of sequences, time_steps, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51180, 1, 15)\n",
      "(17061, 1, 15)\n",
      "(51180,)\n",
      "(17061,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = 15\n",
    "num_features = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0712 21:18:22.687875 17924 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the LSTM network...\n"
     ]
    }
   ],
   "source": [
    "print('Building the LSTM network...')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(num_neurons, input_shape=(1, num_features), return_sequences=True))\n",
    "# model.add(LSTM(16, input_shape=(1, 15), dropout=0.35, recurrent_dropout=0.35, return_sequences=True))\n",
    "\n",
    "# Note:\n",
    "# Need to do return_sequences=False for the layer *before* dense\n",
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "model.add(LSTM(num_neurons, input_shape=(1, num_features), return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 15)             1860      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 15)                1860      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 3,736\n",
      "Trainable params: 3,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "inputs:  (None, 1, 15)\n",
      "outputs:  (None, 1)\n",
      "actual inputs:  (51180, 1, 15)\n",
      "actual outputs:  (51180,)\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "print(\"inputs: \" , model.input_shape)\n",
    "\n",
    "print(\"outputs: \", model.output_shape)\n",
    "\n",
    "print(\"actual inputs: \", np.shape(X_train))\n",
    "\n",
    "print(\"actual outputs: \", np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0712 21:18:23.461098 17924 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0712 21:18:23.473166 17924 deprecation.py:323] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.05)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "\n",
    "              optimizer=opt,\n",
    "\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51180, 1, 15)\n",
      "[[[4.20012648e-01 4.88338496e-01 3.27825507e-01 4.49455827e-01\n",
      "   5.61460096e-02 1.63325736e-01 1.75204978e-01 1.60526926e-01\n",
      "   4.96649262e-02 1.47956418e-02 8.71571496e-01 9.96753928e-01\n",
      "   8.72149806e-01 3.16895905e-04 1.60564346e-03]]\n",
      "\n",
      " [[3.79009922e-01 5.75438532e-01 3.36417722e-01 7.04774479e-01\n",
      "   4.83079389e-02 2.72436834e-01 2.97668198e-01 2.75033395e-01\n",
      "   2.01866546e-02 6.43436110e-03 7.88703033e-01 9.94948280e-01\n",
      "   7.88766009e-01 1.44568210e-04 8.55717074e-04]]\n",
      "\n",
      " [[4.22349601e-01 4.65221860e-01 3.83124046e-01 7.23918851e-01\n",
      "   3.93591387e-02 5.33906064e-01 5.61144386e-01 5.40930435e-01\n",
      "   1.31562718e-02 6.37353777e-03 8.49431795e-01 9.96193438e-01\n",
      "   8.45810055e-01 3.49431214e-04 1.45515298e-03]]\n",
      "\n",
      " [[9.64520106e-02 3.92982448e-01 5.11125905e-02 8.42094274e-02\n",
      "   1.13563070e-02 1.94689576e-01 1.91641953e-01 1.78084078e-01\n",
      "   8.09932985e-02 1.23253134e-01 1.07652330e-01 9.78007049e-01\n",
      "   9.15327273e-02 8.43231646e-04 4.83750979e-03]]\n",
      "\n",
      " [[2.06076052e-01 5.00309618e-01 1.14342362e-01 2.41183628e-01\n",
      "   1.94243552e-02 4.64223794e-02 7.63505263e-02 4.78128476e-02\n",
      "   1.26217983e-02 3.51781170e-03 8.07585189e-01 9.95352754e-01\n",
      "   8.07549825e-01 1.90834017e-04 1.01670050e-03]]\n",
      "\n",
      " [[1.32143630e-01 5.38905992e-01 6.47719879e-02 1.51488532e-02\n",
      "   6.31907277e-02 2.77482321e-01 3.04723692e-01 2.83466062e-01\n",
      "   1.58697529e-02 2.31606871e-03 7.67993170e-01 9.93979461e-01\n",
      "   7.59589124e-01 6.22349728e-04 3.66161754e-03]]\n",
      "\n",
      " [[4.71212997e-01 5.57481850e-01 4.80281979e-01 9.31613785e-01\n",
      "   2.89830247e-02 4.43944441e-01 4.18871509e-01 4.30007924e-01\n",
      "   1.25066809e-01 1.64008482e-01 5.18036687e-01 9.87975730e-01\n",
      "   5.06778239e-01 6.63441724e-04 3.89098015e-03]]\n",
      "\n",
      " [[3.63713550e-01 4.94117625e-01 2.57325419e-01 5.11562124e-01\n",
      "   2.77033507e-02 3.09898116e-01 3.32286639e-01 3.12989683e-01\n",
      "   2.58191835e-02 1.28636931e-02 3.69325199e-01 9.84104804e-01\n",
      "   3.61013698e-01 9.88794820e-04 3.66815857e-03]]\n",
      "\n",
      " [[3.98980200e-01 6.18782241e-01 4.82485145e-01 8.78679823e-01\n",
      "   1.57359638e-01 4.46301599e-02 6.99346785e-02 4.70274867e-02\n",
      "   2.24478888e-02 1.89573737e-03 8.37964076e-01 9.95975630e-01\n",
      "   8.35410313e-01 2.93315267e-04 1.35222050e-03]]\n",
      "\n",
      " [[4.38283300e-01 5.40763639e-01 6.87376074e-01 9.75398966e-01\n",
      "   6.46088146e-02 4.92860343e-03 3.79717393e-02 3.90785410e-03\n",
      "   6.45479587e-03 2.46142698e-03 8.22762199e-01 9.95738146e-01\n",
      "   8.22177030e-01 1.67352876e-04 1.43685574e-03]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "\n",
    "print(X_train[0:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like the data The data is not formated correctly..\n",
    "# for some reason, all of the values in a given index (of which the feature measurements shouold be different, are all the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM...\n",
      "Train on 51180 samples, validate on 17061 samples\n",
      "Epoch 1/5\n",
      "38314/51180 [=====================>........] - ETA: 28s - loss: 0.4907 - acc: 0.7497"
     ]
    }
   ],
   "source": [
    "print('Training LSTM...')\n",
    "\n",
    "batch_size = 2 # I think I want to use batch_size = 1\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('score:', score)\n",
    "\n",
    "print('accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern in dataX:\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(alphabet))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manager.train_model()\n",
    "\n",
    "# manager.test_model()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
