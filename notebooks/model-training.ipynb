{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "# module = os.path.abspath('/home/learner/DLA_project/src/main')\n",
    "module = os.path.abspath(\"C:/Users\\\\18145\\\\development\\\\wesad_experiments\\\\src\\\\main\")\n",
    "if module not in sys.path:\n",
    "    sys.path.append(module)\n",
    "from DataManager import DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from S2\n",
      "\tPath=C:\\WESAD\\S2\\S2.pkl\n",
      "Loading data from S3\n",
      "\tPath=C:\\WESAD\\S3\\S3.pkl\n",
      "Loading data from S4\n",
      "\tPath=C:\\WESAD\\S4\\S4.pkl\n",
      "Loading data from S5\n",
      "\tPath=C:\\WESAD\\S5\\S5.pkl\n",
      "Loading data from S6\n",
      "\tPath=C:\\WESAD\\S6\\S6.pkl\n",
      "Loading data from S7\n",
      "\tPath=C:\\WESAD\\S7\\S7.pkl\n",
      "Loading data from S8\n",
      "\tPath=C:\\WESAD\\S8\\S8.pkl\n",
      "Loading data from S9\n",
      "\tPath=C:\\WESAD\\S9\\S9.pkl\n",
      "Loading data from S10\n",
      "\tPath=C:\\WESAD\\S10\\S10.pkl\n",
      "Loading data from S11\n",
      "\tPath=C:\\WESAD\\S11\\S11.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "manager.load_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conputing features..\n",
      "Considering subject  2\n",
      "Considering subject  3\n",
      "Considering subject  4\n",
      "Considering subject  5\n",
      "Considering subject  6\n",
      "Considering subject  7\n",
      "Considering subject  8\n",
      "Considering subject  9\n",
      "Considering subject  10\n",
      "Considering subject  11\n",
      "conputing features..\n",
      "Considering subject  2\n",
      "Considering subject  3\n",
      "Considering subject  4\n",
      "Considering subject  5\n",
      "Considering subject  6\n",
      "Considering subject  7\n",
      "Considering subject  8\n",
      "Considering subject  9\n",
      "Considering subject  10\n",
      "Considering subject  11\n"
     ]
    }
   ],
   "source": [
    "manager.compute_features();\n",
    "manager.compute_features_stress();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10  subjects\n",
      "there are  44461  values for  a_mean\n",
      "there are  44461  values for  a_std\n",
      "there are  44461  values for  a_maxx\n",
      "there are  44461  values for  a_maxy\n",
      "there are  44461  values for  a_maxz\n",
      "there are  44461  values for  e_max\n",
      "there are  44461  values for  e_min\n",
      "there are  44461  values for  e_mean\n",
      "there are  44461  values for  e_range\n",
      "there are  44461  values for  e_std\n",
      "there are  44461  values for  t_max\n",
      "there are  44461  values for  t_min\n",
      "there are  44461  values for  t_mean\n",
      "there are  44461  values for  t_range\n",
      "there are  44461  values for  t_std\n"
     ]
    }
   ],
   "source": [
    "print(\"We have\", len(manager.SUBJECTS), \" subjects\")\n",
    "\n",
    "for feature in manager.FEATURES.keys():\n",
    "    print(\"there are \", len(manager.FEATURES[feature]), \" values for \", feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets go ahead and reshape this data \n",
    "X1 = (   manager.FEATURES['a_mean'], manager.FEATURES['a_std'], manager.FEATURES['a_maxx'], manager.FEATURES['a_maxy'], manager.FEATURES['a_maxz'],\\\n",
    "                  manager.FEATURES['e_max'], manager.FEATURES['e_min'], manager.FEATURES['e_mean'], manager.FEATURES['e_range'], manager.FEATURES['e_std'],\\\n",
    "                  manager.FEATURES['t_max'], manager.FEATURES['t_min'], manager.FEATURES['t_mean'], manager.FEATURES['t_range'], manager.FEATURES['t_std'] )\n",
    "X1 = np.reshape(X1, (len(manager.FEATURES['a_mean'])  ,15))\n",
    "\n",
    "X2 = (   manager.STRESS_FEATURES['a_mean'], manager.STRESS_FEATURES['a_std'], manager.STRESS_FEATURES['a_maxx'], manager.STRESS_FEATURES['a_maxy'], manager.STRESS_FEATURES['a_maxz'],\\\n",
    "                  manager.STRESS_FEATURES['e_max'], manager.STRESS_FEATURES['e_min'], manager.STRESS_FEATURES['e_mean'], manager.STRESS_FEATURES['e_range'], manager.STRESS_FEATURES['e_std'],\\\n",
    "                  manager.STRESS_FEATURES['t_max'], manager.STRESS_FEATURES['t_min'], manager.STRESS_FEATURES['t_mean'], manager.STRESS_FEATURES['t_range'], manager.STRESS_FEATURES['t_std'] )\n",
    "X2 = np.reshape(X2, (len(manager.STRESS_FEATURES['a_mean'])  ,15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pip\n",
    "\n",
    "# try:\n",
    "#     import keras\n",
    "# except ImportError:\n",
    "#     ! sudo pip3 install keras\n",
    "# try:\n",
    "#     import h5py\n",
    "# except ImportError:\n",
    "#     ! sudo pip3 install h5py\n",
    "# try:\n",
    "#     import ibmiotf\n",
    "# except ImportError:\n",
    "#     ! sudo pip3 install ibmiotf\n",
    "# try:\n",
    "#     import tensorflow\n",
    "# except ImportError:\n",
    "#     ! sudo pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import sklearn\n",
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0712 18:16:52.130266 17776 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0712 18:16:52.132154 17776 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0712 18:16:52.133272 17776 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0712 18:16:52.209442 17776 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8, )\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "session = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be better to have our data scaled between 0 and 1, so lets go ahead and create a function to \n",
    "normalize the data that way now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 is the baseline data\n",
    "# x2 is the stress data\n",
    "\n",
    "y1 = [0] * len(X1)\n",
    "y2 = [1] * len(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44461\n",
      "23780\n"
     ]
    }
   ],
   "source": [
    "print(len(y1))\n",
    "print(len(y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to concat the data between baseline and stress so that we can split it into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68241, 15)\n",
      "(68241,)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((X1, X2), axis=0)\n",
    "print(np.shape(X))\n",
    "\n",
    "y = np.concatenate((y1,y2), axis=0)\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data up in train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# since we don't have the same number of samples for x and y, \n",
    "# we will drop off some x values for creating the sample\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54592, 15)\n",
      "(13649, 15)\n",
      "(54592,)\n",
      "(13649,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be\n",
    "\n",
    "# input_shape=(number of sequences=?, time_steps=None, features=15)\n",
    "\n",
    "# target=(number of sequences, time_steps, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54592, 1, 15)\n",
      "(13649, 1, 15)\n",
      "(54592,)\n",
      "(13649,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    return scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to scale the data and hope we get better results.\n",
    "1. fit the scaler to the training data (fit_transform)\n",
    "2. transform training data with the scaler\n",
    "3. fit the model with transformed data\n",
    "4. transform test data with the scaler\n",
    "5. predict using model and output of (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0712 18:16:52.469110 17776 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the LSTM network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0712 18:16:53.113138 17776 deprecation.py:506] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "print('Building the LSTM network...')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, input_shape=(1, 15), return_sequences=True))\n",
    "model.add(LSTM(32, input_shape=(1, 15), dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "\n",
    "# Note:\n",
    "# Need to do return_sequences=False for the layer *before* dense\n",
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "model.add(LSTM(32, input_shape=(1, 15), return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 32)             6144      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 32)             8320      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 22,817\n",
      "Trainable params: 22,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "inputs:  (None, 1, 15)\n",
      "outputs:  (None, 1)\n",
      "actual inputs: \n",
      "actual outputs: \n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "print(\"inputs: \" , model.input_shape)\n",
    "\n",
    "print(\"outputs: \", model.output_shape)\n",
    "\n",
    "print(\"actual inputs: \", np.shape(X_train))\n",
    "\n",
    "print(\"actual outputs: \", np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0712 18:16:53.936480 17776 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0712 18:16:53.980187 17776 deprecation.py:323] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "\n",
    "              optimizer='adam',\n",
    "\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM...\n",
      "Train on 54592 samples, validate on 13649 samples\n",
      "Epoch 1/5\n",
      "54592/54592 [==============================] - 386s 7ms/step - loss: 0.6309 - acc: 0.6550 - val_loss: 0.6360 - val_acc: 0.6472\n",
      "Epoch 2/5\n",
      "54592/54592 [==============================] - 378s 7ms/step - loss: 0.6302 - acc: 0.6558 - val_loss: 0.6338 - val_acc: 0.6483\n",
      "Epoch 3/5\n",
      "54592/54592 [==============================] - 378s 7ms/step - loss: 0.6293 - acc: 0.6556 - val_loss: 0.6339 - val_acc: 0.6501\n",
      "Epoch 4/5\n",
      "54592/54592 [==============================] - 380s 7ms/step - loss: 0.6276 - acc: 0.6554 - val_loss: 0.6309 - val_acc: 0.6472\n",
      "Epoch 5/5\n",
      "54592/54592 [==============================] - 691s 13ms/step - loss: 0.6264 - acc: 0.6562 - val_loss: 0.6344 - val_acc: 0.6458\n",
      "13649/13649 [==============================] - 27s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "print('Training LSTM...')\n",
    "\n",
    "batch_size = 1 # I think I want to use batch_size = 1\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('score:', score)\n",
    "\n",
    "print('accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern in dataX:\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(alphabet))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manager.train_model()\n",
    "\n",
    "# manager.test_model()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
