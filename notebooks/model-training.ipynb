{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "module = os.path.abspath('/home/learner/DLA_project/src/main')\n",
    "# module = os.path.abspath(\"C:/Users\\\\18145\\\\development\\\\wesad_experiments\\\\src\\\\main\")\n",
    "if module not in sys.path:\n",
    "    sys.path.append(module)\n",
    "from DataManager import DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from S2\n",
      "\tPath=/media/learner/6663-3462/WESAD/S2/S2.pkl\n",
      "Loading data from S3\n",
      "\tPath=/media/learner/6663-3462/WESAD/S3/S3.pkl\n",
      "Loading data from S4\n",
      "\tPath=/media/learner/6663-3462/WESAD/S4/S4.pkl\n",
      "Loading data from S5\n",
      "\tPath=/media/learner/6663-3462/WESAD/S5/S5.pkl\n",
      "Loading data from S6\n",
      "\tPath=/media/learner/6663-3462/WESAD/S6/S6.pkl\n",
      "Loading data from S7\n",
      "\tPath=/media/learner/6663-3462/WESAD/S7/S7.pkl\n",
      "Loading data from S8\n",
      "\tPath=/media/learner/6663-3462/WESAD/S8/S8.pkl\n",
      "Loading data from S9\n",
      "\tPath=/media/learner/6663-3462/WESAD/S9/S9.pkl\n",
      "Loading data from S10\n",
      "\tPath=/media/learner/6663-3462/WESAD/S10/S10.pkl\n",
      "Loading data from S11\n",
      "\tPath=/media/learner/6663-3462/WESAD/S11/S11.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "manager.load_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conputing features..\n",
      "Considering subject  2\n",
      "Considering subject  3\n",
      "Considering subject  4\n",
      "Considering subject  5\n",
      "Considering subject  6\n",
      "Considering subject  7\n",
      "Considering subject  8\n",
      "Considering subject  9\n",
      "Considering subject  10\n",
      "Considering subject  11\n",
      "conputing features..\n",
      "Considering subject  2\n",
      "Considering subject  3\n",
      "Considering subject  4\n",
      "Considering subject  5\n",
      "Considering subject  6\n",
      "Considering subject  7\n",
      "Considering subject  8\n",
      "Considering subject  9\n",
      "Considering subject  10\n",
      "Considering subject  11\n"
     ]
    }
   ],
   "source": [
    "manager.compute_features();\n",
    "manager.compute_features_stress();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10  subjects\n",
      "there are  44461  values for  a_mean\n",
      "there are  44461  values for  a_std\n",
      "there are  44461  values for  a_maxx\n",
      "there are  44461  values for  a_maxy\n",
      "there are  44461  values for  a_maxz\n",
      "there are  44461  values for  e_max\n",
      "there are  44461  values for  e_min\n",
      "there are  44461  values for  e_mean\n",
      "there are  44461  values for  e_range\n",
      "there are  44461  values for  e_std\n",
      "there are  44461  values for  t_max\n",
      "there are  44461  values for  t_min\n",
      "there are  44461  values for  t_mean\n",
      "there are  44461  values for  t_range\n",
      "there are  44461  values for  t_std\n"
     ]
    }
   ],
   "source": [
    "print(\"We have\", len(manager.SUBJECTS), \" subjects\")\n",
    "\n",
    "for feature in manager.FEATURES.keys():\n",
    "    print(\"there are \", len(manager.FEATURES[feature]), \" values for \", feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets go ahead and reshape this data \n",
    "X = (   manager.FEATURES['a_mean'], manager.FEATURES['a_std'], manager.FEATURES['a_maxx'], manager.FEATURES['a_maxy'], manager.FEATURES['a_maxz'],\\\n",
    "                  manager.FEATURES['e_max'], manager.FEATURES['e_min'], manager.FEATURES['e_mean'], manager.FEATURES['e_range'], manager.FEATURES['e_std'],\\\n",
    "                  manager.FEATURES['t_max'], manager.FEATURES['t_min'], manager.FEATURES['t_mean'], manager.FEATURES['t_range'], manager.FEATURES['t_std'] )\n",
    "X = np.reshape(X, (len(manager.FEATURES['a_mean'])  ,15))\n",
    "\n",
    "y = (   manager.STRESS_FEATURES['a_mean'], manager.STRESS_FEATURES['a_std'], manager.STRESS_FEATURES['a_maxx'], manager.STRESS_FEATURES['a_maxy'], manager.STRESS_FEATURES['a_maxz'],\\\n",
    "                  manager.STRESS_FEATURES['e_max'], manager.STRESS_FEATURES['e_min'], manager.STRESS_FEATURES['e_mean'], manager.STRESS_FEATURES['e_range'], manager.STRESS_FEATURES['e_std'],\\\n",
    "                  manager.STRESS_FEATURES['t_max'], manager.STRESS_FEATURES['t_min'], manager.STRESS_FEATURES['t_mean'], manager.STRESS_FEATURES['t_range'], manager.STRESS_FEATURES['t_std'] )\n",
    "y = np.reshape(y, (len(manager.STRESS_FEATURES['a_mean'])  ,15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9eff10fccb79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "targets_base = [0] * len(X)\n",
    "targets_stress = [1] * len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "\n",
    "try:\n",
    "    import keras\n",
    "except ImportError:\n",
    "    ! sudo pip3 install keras\n",
    "try:\n",
    "    import h5py\n",
    "except ImportError:\n",
    "    ! sudo pip3 install h5py\n",
    "try:\n",
    "    import ibmiotf\n",
    "except ImportError:\n",
    "    ! sudo pip3 install ibmiotf\n",
    "try:\n",
    "    import tensorflow\n",
    "except ImportError:\n",
    "    ! sudo pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import sklearn\n",
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be better to have our data scaled between 0 and 1, so lets go ahead and create a function to \n",
    "normalize the data that way now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    return scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Embedding\n",
    "\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data up in train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# since we don't have the same number of samples for x and y, \n",
    "# we will drop off some x values for creating the sample\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X[0:len(y)], y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19024, 15)\n",
      "(4756, 15)\n",
      "(19024, 15)\n",
      "(4756, 15)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_base_train = [0] * len(X_train)\n",
    "t_stress_train = [0] * len(y_train)\n",
    "\n",
    "t_base_test = [0] * len(X_test)\n",
    "t_stress_test = [0] * len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 9512, 15)\n"
     ]
    }
   ],
   "source": [
    "X = [X_train, y_train]\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the LSTM network...\n"
     ]
    }
   ],
   "source": [
    "print('Build the LSTM network...')\n",
    "max_features = 20000\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(2, input_dim=2, activation='relu'))\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "# https://stackoverflow.com/questions/49623436/valueerror-error-when-checking-target-expected-dense-2-to-have-3-dimensions-b\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, None, 128)         131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, None, 1)           129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "\n",
    "              optimizer='adam',\n",
    "\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_1 to have shape (1,) but got array with shape (15,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cf91e903ac8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m score, acc = model.evaluate(X_test, y_test,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_1 to have shape (1,) but got array with shape (15,)"
     ]
    }
   ],
   "source": [
    "print('Training LSTM...')\n",
    "\n",
    "batch_size = 1 # I think I want to use batch_size = 1\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('score:', score)\n",
    "\n",
    "print('accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test))\n",
    "\n",
    "# score, acc = model.evaluate(x_test, y_test,\n",
    "\n",
    "#                             batch_size=batch_size)\n",
    "\n",
    "print('Test score:', score)\n",
    "\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((x_train))\n",
    "\n",
    "features go across to the right, they have 80 features\n",
    "time goes down , number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train[0]))\n",
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manager.train_model()\n",
    "\n",
    "# manager.test_model()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
