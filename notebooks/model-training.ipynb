{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "# module = os.path.abspath('/home/learner/DLA_project/src/main')\n",
    "module = os.path.abspath(\"C:/Users\\\\18145\\\\development\\\\wesad_experiments\\\\src\\\\main\")\n",
    "if module not in sys.path:\n",
    "    sys.path.append(module)\n",
    "from DataManager import DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from S2\n",
      "\tPath=C:\\WESAD\\S2\\S2.pkl\n",
      "Loading data from S3\n",
      "\tPath=C:\\WESAD\\S3\\S3.pkl\n",
      "Loading data from S4\n",
      "\tPath=C:\\WESAD\\S4\\S4.pkl\n",
      "Loading data from S5\n",
      "\tPath=C:\\WESAD\\S5\\S5.pkl\n",
      "Loading data from S6\n",
      "\tPath=C:\\WESAD\\S6\\S6.pkl\n",
      "Loading data from S7\n",
      "\tPath=C:\\WESAD\\S7\\S7.pkl\n",
      "Loading data from S8\n",
      "\tPath=C:\\WESAD\\S8\\S8.pkl\n",
      "Loading data from S9\n",
      "\tPath=C:\\WESAD\\S9\\S9.pkl\n",
      "Loading data from S10\n",
      "\tPath=C:\\WESAD\\S10\\S10.pkl\n",
      "Loading data from S11\n",
      "\tPath=C:\\WESAD\\S11\\S11.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "manager.load_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conputing features..\n",
      "Considering subject  2\n",
      "Considering subject  3\n",
      "Considering subject  4\n",
      "Considering subject  5\n",
      "Considering subject  6\n",
      "Considering subject  7\n",
      "Considering subject  8\n",
      "Considering subject  9\n",
      "Considering subject  10\n",
      "Considering subject  11\n",
      "conputing features..\n",
      "Considering subject  2\n",
      "Considering subject  3\n",
      "Considering subject  4\n",
      "Considering subject  5\n",
      "Considering subject  6\n",
      "Considering subject  7\n",
      "Considering subject  8\n",
      "Considering subject  9\n",
      "Considering subject  10\n",
      "Considering subject  11\n"
     ]
    }
   ],
   "source": [
    "manager.compute_features();\n",
    "manager.compute_features_stress();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10  subjects\n",
      "there are  44461  values for  a_mean\n",
      "[0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773, 0.6426000595092773]\n",
      "there are  44461  values for  a_std\n",
      "[-0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962, -0.04559999704360962]\n",
      "there are  44461  values for  a_maxx\n",
      "[-0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928, -0.6898000240325928]\n",
      "there are  44461  values for  a_maxy\n",
      "[-0.1681766395512081, -0.16820373953666, -0.1682159157196681, -0.16822052995931536, -0.16817386801469902, -0.16810921560015002, -0.16804839175513808, -0.16799597744998485, -0.167943796508369, -0.16789020597508975, -0.16785491549826792]\n",
      "there are  44461  values for  a_maxz\n",
      "[0.018150791410807637, 0.018153852199080042, 0.018155388200807383, 0.01816366217156312, 0.018098480896898087, 0.018049710117182687, 0.018029910512462825, 0.017971771785544866, 0.01794856213048406, 0.01793648580576654, 0.017917797155686754]\n",
      "there are  44461  values for  e_max\n",
      "[1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625, 1.3706207275390625]\n",
      "there are  44461  values for  e_min\n",
      "[1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875, 1.042938232421875]\n",
      "there are  44461  values for  e_mean\n",
      "[1.256753022330148, 1.2564663750784737, 1.2561790829613095, 1.2558757509504046, 1.2555773689633325, 1.2552835464477539, 1.2549859183175223, 1.2546887534005302, 1.2544013522920154, 1.2541091101510184, 1.2538137708391461]\n",
      "there are  44461  values for  e_range\n",
      "[0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875, 0.3276824951171875]\n",
      "there are  44461  values for  e_std\n",
      "[0.027996115056521168, 0.027978663566655466, 0.027968531671524306, 0.027930017594235457, 0.027900964709956896, 0.02788097863880627, 0.02786017275544809, 0.027840284597997103, 0.027826475246974486, 0.027801530045377415, 0.02779012605506253]\n",
      "there are  44461  values for  t_max\n",
      "[28.456024, 28.456024, 28.456024, 28.463135, 28.463135, 28.557465, 28.557465, 28.557465, 28.557465, 28.557465, 28.557465]\n",
      "there are  44461  values for  t_min\n",
      "[28.045258, 28.045258, 28.045258, 28.045258, 28.045258, 28.045258, 28.045258, 28.045258, 28.045258, 28.045258, 28.045258]\n",
      "there are  44461  values for  t_mean\n",
      "[28.21592, 28.21635, 28.216797, 28.217257, 28.217714, 28.218203, 28.218681, 28.21911, 28.2196, 28.220066, 28.22053]\n",
      "there are  44461  values for  t_range\n",
      "[0.4107666, 0.4107666, 0.4107666, 0.4178772, 0.4178772, 0.51220703, 0.51220703, 0.51220703, 0.51220703, 0.51220703, 0.51220703]\n",
      "there are  44461  values for  t_std\n",
      "[0.055632006, 0.055853903, 0.056076307, 0.05630139, 0.05653354, 0.056806758, 0.057019647, 0.05716957, 0.057364658, 0.057513, 0.057683818]\n"
     ]
    }
   ],
   "source": [
    "print(\"We have\", len(manager.SUBJECTS), \" subjects\")\n",
    "\n",
    "for feature in manager.FEATURES.keys():\n",
    "    print(\"there are \", len(manager.FEATURES[feature]), \" values for \", feature)\n",
    "    print(manager.FEATURES[feature][3277:3288])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44461, 15)\n",
      "(23780, 15)\n"
     ]
    }
   ],
   "source": [
    "# Lets go ahead and reshape this data such that we have\n",
    "# samples, features = [N, 15]\n",
    "\n",
    "X1 = []\n",
    "X2 = []\n",
    "for i in range(0, ) \n",
    "\n",
    "\n",
    "X1 = np.hstack([manager.FEATURES['a_mean'], manager.FEATURES['a_std'], manager.FEATURES['a_maxx'], manager.FEATURES['a_maxy'], manager.FEATURES['a_maxz'],\\\n",
    "                  manager.FEATURES['e_max'], manager.FEATURES['e_min'], manager.FEATURES['e_mean'], manager.FEATURES['e_range'], manager.FEATURES['e_std'],\\\n",
    "                  manager.FEATURES['t_max'], manager.FEATURES['t_min'], manager.FEATURES['t_mean'], manager.FEATURES['t_range'], manager.FEATURES['t_std']] )\n",
    "print(np.shape(X1))\n",
    "\n",
    "# X1 = np.reshape(X1, (len(manager.FEATURES['a_mean']), 15))\n",
    "\n",
    "print(np.shape(X1))\n",
    "\n",
    "\n",
    "X2 = np.hstack([manager.STRESS_FEATURES['a_mean'], manager.STRESS_FEATURES['a_std'], manager.STRESS_FEATURES['a_maxx'], manager.STRESS_FEATURES['a_maxy'], manager.STRESS_FEATURES['a_maxz'],\\\n",
    "                  manager.STRESS_FEATURES['e_max'], manager.STRESS_FEATURES['e_min'], manager.STRESS_FEATURES['e_mean'], manager.STRESS_FEATURES['e_range'], manager.STRESS_FEATURES['e_std'],\\\n",
    "                  manager.STRESS_FEATURES['t_max'], manager.STRESS_FEATURES['t_min'], manager.STRESS_FEATURES['t_mean'], manager.STRESS_FEATURES['t_range'], manager.STRESS_FEATURES['t_std']] )\n",
    "print(np.shape(X1))\n",
    "\n",
    "# X2 = np.reshape(X2, (len(manager.STRESS_FEATURES['a_mean']), 15))\n",
    "\n",
    "print(np.shape(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005]\n",
      " [1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005]\n",
      " [1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005]\n",
      " [1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005]\n",
      " [1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005]\n",
      " [1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005]\n",
      " [1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005]\n",
      " [1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005]\n",
      " [1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005 1.14540005 1.14540005 1.14540005\n",
      "  1.14540005 1.14540005 1.14540005]\n",
      " [1.14540005 1.14540005 1.14540005 0.87559998 0.79779994 0.74020004\n",
      "  0.72940004 0.69459999 0.66980004 0.65380001 0.65380001 0.65380001\n",
      "  0.64579999 0.64579999 0.64579999]\n",
      " [0.64579999 0.64419997 0.64419997 0.64419997 0.64419997 0.64419997\n",
      "  0.64419997 0.64419997 0.64419997 0.64419997 0.64419997 0.64419997\n",
      "  0.64419997 0.64419997 0.64419997]\n",
      " [0.64419997 0.64419997 0.64419997 0.64419997 0.64419997 0.64419997\n",
      "  0.64419997 0.64419997 0.64419997 0.64419997 0.64419997 0.64419997\n",
      "  0.64419997 0.64419997 0.64419997]\n",
      " [0.64419997 0.64419997 0.64419997 0.64419997 0.64419997 0.64419997\n",
      "  0.64419997 0.64419997 0.64419997 0.64419997 0.64419997 0.64419997\n",
      "  0.64419997 0.64419997 0.64419997]\n",
      " [0.64419997 0.64419997 0.64419997 0.64419997 0.64419997 0.64419997\n",
      "  0.64419997 0.64419997 0.64419997 0.64419997 0.64419997 0.64419997\n",
      "  0.64419997 0.64419997 0.64419997]\n",
      " [0.64419997 0.64419997 0.64419997 0.64419997 0.64419997 0.64419997\n",
      "  0.64419997 0.64419997 0.64419997 0.64419997 0.64419997 0.64419997\n",
      "  0.64419997 0.64419997 0.64419997]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246, 1.145400047302246]\n",
      "[-0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219, -0.06319999694824219]\n",
      "[0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667, 0.6109999418258667]\n"
     ]
    }
   ],
   "source": [
    "print(manager.FEATURES['a_mean'][100:110])\n",
    "\n",
    "print(manager.FEATURES['a_std'][400:410])\n",
    "\n",
    "print(manager.FEATURES['a_maxx'][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pip\n",
    "\n",
    "# try:\n",
    "#     import keras\n",
    "# except ImportError:\n",
    "#     ! sudo pip3 install keras\n",
    "# try:\n",
    "#     import h5py\n",
    "# except ImportError:\n",
    "#     ! sudo pip3 install h5py\n",
    "# try:\n",
    "#     import ibmiotf\n",
    "# except ImportError:\n",
    "#     ! sudo pip3 install ibmiotf\n",
    "# try:\n",
    "#     import tensorflow\n",
    "# except ImportError:\n",
    "#     ! sudo pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import sklearn\n",
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0712 20:01:39.512037 18800 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0712 20:01:39.514793 18800 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0712 20:01:39.517055 18800 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0712 20:01:39.587185 18800 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8, )\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "session = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 is the baseline data\n",
    "# x2 is the stress data\n",
    "\n",
    "y1 = [0] * len(X1)\n",
    "y2 = [1] * len(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44461\n",
      "23780\n"
     ]
    }
   ],
   "source": [
    "print(len(y1))\n",
    "print(len(y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to concat the data between baseline and stress so that we can split it into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68241, 15)\n",
      "(68241,)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((X1, X2), axis=0)\n",
    "print(np.shape(X))\n",
    "\n",
    "y = np.concatenate((y1,y2), axis=0)\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data up in train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# since we don't have the same number of samples for x and y, \n",
    "# we will drop off some x values for creating the sample\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51180, 15)\n",
      "(17061, 15)\n",
      "(51180,)\n",
      "(17061,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to scale the data and hope we get better results.\n",
    "1. fit the scaler to the training data (fit_transform)\n",
    "2. transform training data with the scaler\n",
    "3. fit the model with transformed data\n",
    "4. transform test data with the scaler\n",
    "5. predict using model and output of (4)\n",
    "\n",
    "It will be better to have our data scaled between 0 and 1, so lets go ahead and create a function to \n",
    "normalize the data that way now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize(data):\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     return scaler.fit_transform(data)\n",
    "# X_train = normalize(X_train)\n",
    "# X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be\n",
    "\n",
    "# input_shape=(number of sequences=?, time_steps=None, features=15)\n",
    "\n",
    "# target=(number of sequences, time_steps, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51180, 1, 15)\n",
      "(17061, 1, 15)\n",
      "(51180,)\n",
      "(17061,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = 15\n",
    "num_features = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0712 20:01:39.882449 18800 deprecation_wrapper.py:119] From C:\\Users\\18145\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the LSTM network...\n"
     ]
    }
   ],
   "source": [
    "print('Building the LSTM network...')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(num_neurons, input_shape=(1, num_features), return_sequences=True))\n",
    "# model.add(LSTM(16, input_shape=(1, 15), dropout=0.35, recurrent_dropout=0.35, return_sequences=True))\n",
    "\n",
    "# Note:\n",
    "# Need to do return_sequences=False for the layer *before* dense\n",
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "model.add(LSTM(num_neurons, input_shape=(1, num_features), return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 16)             2048      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 4,177\n",
      "Trainable params: 4,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "inputs:  (None, 1, 15)\n",
      "outputs:  (None, 1)\n",
      "actual inputs:  (51180, 1, 15)\n",
      "actual outputs:  (51180,)\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "print(\"inputs: \" , model.input_shape)\n",
    "\n",
    "print(\"outputs: \", model.output_shape)\n",
    "\n",
    "print(\"actual inputs: \", np.shape(X_train))\n",
    "\n",
    "print(\"actual outputs: \", np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.05)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "\n",
    "              optimizer=opt,\n",
    "\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51180, 1, 15)\n",
      "[[[34.4163208  34.4163208  34.4163208  34.4163208  34.4163208\n",
      "   34.4163208  34.4163208  34.4163208  34.4163208  34.4163208\n",
      "   34.4163208  34.4163208  34.4163208  34.4163208  34.4163208 ]]\n",
      "\n",
      " [[ 0.30010986  0.30010986  0.30010986  0.30010986  0.30010986\n",
      "    0.30010986  0.30010986  0.31079102  0.31079102  0.31079102\n",
      "    0.31079102  0.31079102  0.31079102  0.31079102  0.31079102]]\n",
      "\n",
      " [[ 0.3452301   0.3452301   0.3452301   0.3452301   0.3452301\n",
      "    0.3452301   0.3452301   0.3452301   0.3452301   0.3452301\n",
      "    0.3452301   0.3452301   0.3452301   0.3452301   0.3452301 ]]\n",
      "\n",
      " [[ 0.64260006  0.64260006  0.64260006  0.64260006  0.64260006\n",
      "    0.64260006  0.64260006  0.64260006  0.64260006  0.64260006\n",
      "    0.64260006  0.64260006  0.64260006  0.64260006  0.64260006]]\n",
      "\n",
      " [[28.20196533 28.20196533 28.20196533 28.20196533 28.20196533\n",
      "   28.20196533 28.20196533 28.20196533 28.20196533 28.20196533\n",
      "   28.20196533 28.20196533 28.20196533 28.20196533 28.20196533]]\n",
      "\n",
      " [[ 6.5112908   6.51084975  6.51041554  6.5099777   6.50953298\n",
      "    6.5090392   6.50858452  6.50815809  6.50772421  6.50727633\n",
      "    6.50684551  6.50640675  6.50596001  6.50550724  6.50506131]]\n",
      "\n",
      " [[-0.4138     -0.4138     -0.4138     -0.4138     -0.4138\n",
      "   -0.4138     -0.4138     -0.4138     -0.4138     -0.4138\n",
      "   -0.4138     -0.4138     -0.4138     -0.4138     -0.4138    ]]\n",
      "\n",
      " [[-0.65320003 -0.65320003 -0.65320003 -0.65320003 -0.65320003\n",
      "   -0.65320003 -0.65320003 -0.65320003 -0.65320003 -0.65320003\n",
      "   -0.65320003 -0.65320003 -0.65320003 -0.65320003 -0.65320003]]\n",
      "\n",
      " [[34.37954712 34.37954712 34.37954712 34.37954712 34.37954712\n",
      "   34.37954712 34.37954712 34.37954712 34.37954712 34.37954712\n",
      "   34.37954712 34.37954712 34.37954712 34.37954712 34.37954712]]\n",
      "\n",
      " [[ 0.33517456  0.33517456  0.33517456  0.33517456  0.33517456\n",
      "    0.33517456  0.33517456  0.33517456  0.33517456  0.33517456\n",
      "    0.33517456  0.33517456  0.33517456  0.33517456  0.33517456]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "\n",
    "print(X_train[0:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like the data The data is not formated correctly..\n",
    "# for some reason, all of the values in a given index (of which the feature measurements shouold be different, are all the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM...\n",
      "Train on 51180 samples, validate on 17061 samples\n",
      "Epoch 1/5\n",
      "32748/51180 [==================>...........] - ETA: 44s - loss: 0.6417 - acc: 0.6527"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-ed5b9f405d3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m score, acc = model.evaluate(X_test, y_test,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Training LSTM...')\n",
    "\n",
    "batch_size = 2 # I think I want to use batch_size = 1\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('score:', score)\n",
    "\n",
    "print('accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern in dataX:\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(alphabet))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manager.train_model()\n",
    "\n",
    "# manager.test_model()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
